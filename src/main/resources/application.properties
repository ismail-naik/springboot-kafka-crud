
spring.profiles.active=dev
spring.application.name=customer-micro
server.port=8080
# postgres
#spring.datasource.url=${DATABASE_URL}
#spring.datasource.username=admin
#spring.datasource.password=admin
#spring.jpa.generate-ddl=true
#spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation=true
#spring.jpa.show-sql=true

spring.datasource.url=jdbc:mysql://localhost:3306/customer?createDatabaseIfNotExist=true&useSSL=false&allowPublicKeyRetrieval=true
spring.datasource.username=root
spring.datasource.password=rootadmin
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.jpa.generate-ddl=true
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.hibernate.ddl-auto=update
spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.MySQL5Dialect

# user authenticate
username = InventoriesApp
userpass = Password

# admin
useradmin = admin
adminpass = admin


# Cloud Karafka
spring.kafka.bootstrap-servers=localhost:9092
#spring.kafka.properties.security.protocol=SASL_SSL
#spring.kafka.properties.sasl.mechanism=SCRAM-SHA-256
#spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${CLOUDKARAFKA_USERNAME}" password="${CLOUDKARAFKA_PASSWORD}";
spring.kafka.consumer.group-id=customers
spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.consumer.properties.spring.json.trusted.packages=sample.kafka

customers.kafka.post=kafka.post.customer
customers.kafka.put=kafka.put.customer
customers.kafka.patch=kafka.patch.customer
customers.kafka.delete=kafka.delete.customer
